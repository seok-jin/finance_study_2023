{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import datetime\n",
    "import random\n",
    "import pymysql\n",
    "conn = pymysql.connect(host='127.0.0.1', user='root', passwd='1234', db='mysql', charset='utf8')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE sys\")\n",
    "random.seed(datetime.datetime.now())\n",
    "\n",
    "def store(title, content):\n",
    "    cur.execute(\n",
    "        \"INSERT INTO pages (title, content) VALUES (\\\"%s\\\", \\\"%s\\\")\", (title, content))\n",
    "    cur.connection.commit()\n",
    "\n",
    "def getLinks(articleUrl):\n",
    "    html = urlopen(\"http://en.wikipedia.org\"+articleUrl)\n",
    "    bsObj = BeautifulSoup(html,\"html.parser\")\n",
    "    title = bsObj.find('h1').find(\"span\").get_text()\n",
    "    content = bsObj.find(\"div\", {\"id\":\"mw-content-text\"}).find(\"p\").get_text()\n",
    "    store(title,content)\n",
    "    return bsObj.find(\"div\", {\"id\":\"bodyContent\"}).findAll(\"a\", href=re.compile(\"^(/wiki/)((?!:).)*$\"))\n",
    "\n",
    "links = getLinks(\"/wiki/Kevin_Bacon\")\n",
    "try:\n",
    "    while len(links) >0:\n",
    "        newArticle = links[random.randint(0, len(links)-1)].attrs[\"href\"]\n",
    "        print(newArticle)\n",
    "        links = getLinks(newArticle)\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
